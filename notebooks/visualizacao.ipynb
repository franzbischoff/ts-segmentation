{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa73d5f9",
   "metadata": {},
   "source": [
    "# Notebook de Logging, Grid Search e Visualização de Resultados\n",
    "\n",
    "Este notebook consolida: logging estruturado em JSON, grid search e visualizações de métricas / hiperparâmetros."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c562b4",
   "metadata": {},
   "source": [
    "## 1. Exportar Dependências para requirements.txt\n",
    "\n",
    "Opções:\n",
    "1. Congelar tudo (`pip freeze`) – menos controlado.\n",
    "2. Selecionar apenas libs nucleares que importamos.\n",
    "\n",
    "Abaixo: coleta módulos carregados relevantes + interseção com `pip freeze`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f7d7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess, sys, json, textwrap, pathlib\n",
    "from importlib import util\n",
    "\n",
    "CORE = {\"numpy\", \"pandas\", \"scikit-learn\", \"scikit-multiflow\", \"matplotlib\", \"seaborn\"}\n",
    "raw_freeze = subprocess.check_output([sys.executable, '-m', 'pip', 'freeze'], text=True).strip().split('\n",
    "')\n",
    "parsed = {}\n",
    "for line in raw_freeze:\n",
    "    if '==' in line:\n",
    "        pkg, ver = line.split('==', 1)\n",
    "        parsed[pkg.lower()] = line\n",
    "\n",
    "selected = [parsed[p.lower()] for p in CORE if p.lower() in parsed]\n",
    "print('Selecionados:')\n",
    "print('\n",
    "'.join(sorted(selected)))\n",
    "\n",
    "with open('../requirements_minimal.txt', 'w') as f:\n",
    "    f.write('\n",
    "'.join(sorted(selected)) + '\n",
    "')\n",
    "print('Arquivo gravado em requirements_minimal.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc515794",
   "metadata": {},
   "source": [
    "## 2. Configurar Logging JSON Estruturado\n",
    "\n",
    "Criaremos um logger com formatter que serializa dicts para JSON, incluindo campos extra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6a9df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging, logging.config, json, sys, os, time\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "class JsonFormatter(logging.Formatter):\n",
    "    def format(self, record: logging.LogRecord):\n",
    "        base = {\n",
    "            'ts': datetime.now(timezone.utc).isoformat(),\n",
    "            'level': record.levelname,\n",
    "            'logger': record.name,\n",
    "            'msg': record.getMessage(),\n",
    "            'correlation_id': getattr(record, 'correlation_id', None)\n",
    "        }\n",
    "        # Merge extras (safe)\n",
    "        for k, v in record.__dict__.items():\n",
    "            if k.startswith('_') or k in base or k in ('msg','args','exc_info','exc_text','stack_info','levelno','levelname','name','thread','threadName','processName','process','created','msecs','relativeCreated','pathname','filename','module','lineno','funcName'):\n",
    "                continue\n",
    "            try:\n",
    "                json.dumps(v)  # test serializável\n",
    "                base[k] = v\n",
    "            except Exception:\n",
    "                base[k] = repr(v)\n",
    "        if record.exc_info:\n",
    "            base['exception'] = self.formatException(record.exc_info)\n",
    "        return json.dumps(base, ensure_ascii=False)\n",
    "\n",
    "LOG_CFG = {\n",
    " 'version':1,\n",
    " 'disable_existing_loggers': False,\n",
    " 'formatters': {'json': {'()': JsonFormatter}},\n",
    " 'handlers': {\n",
    "    'console': {'class':'logging.StreamHandler','formatter':'json','stream':'ext://sys.stdout'},\n",
    "    'file': {'class':'logging.FileHandler','formatter':'json','filename':'../results/notebook_log.jsonl','mode':'a','encoding':'utf-8'}\n",
    " },\n",
    " 'root': {'handlers':['console','file'],'level':'INFO'}\n",
    "}\n",
    "\n",
    "logging.config.dictConfig(LOG_CFG)\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.info('Logger inicializado', extra={'phase':'init'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945661b5",
   "metadata": {},
   "source": [
    "## 3. Adicionar Correlation ID e Context Manager\n",
    "Usamos `contextvars` para propagar um correlation_id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09c3b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextvars, uuid, functools, contextlib\n",
    "correlation_var = contextvars.ContextVar('correlation_id', default=None)\n",
    "\n",
    "class CorrelationFilter(logging.Filter):\n",
    "    def filter(self, record):\n",
    "        cid = correlation_var.get()\n",
    "        if cid:\n",
    "            record.correlation_id = cid\n",
    "        return True\n",
    "\n",
    "for h in logging.getLogger().handlers:\n",
    "    h.addFilter(CorrelationFilter())\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def correlation_context(cid: str | None = None):\n",
    "    token = correlation_var.set(cid or str(uuid.uuid4()))\n",
    "    try:\n",
    "        yield correlation_var.get()\n",
    "    finally:\n",
    "        correlation_var.reset(token)\n",
    "\n",
    "with correlation_context() as cid:\n",
    "    logger.info('Exemplo de log com correlation id', extra={'cid_demo': True})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4667369f",
   "metadata": {},
   "source": [
    "## 4. Rotação e Compressão de Logs\n",
    "Pós-processamos arquivos rotacionados compactando-os em `.gz`. Exemplo simplificado abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c02d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip, shutil, glob\n",
    "from logging.handlers import TimedRotatingFileHandler\n",
    "\n",
    "class GzipTimedRotatingFileHandler(TimedRotatingFileHandler):\n",
    "    def rotate(self, source, dest):\n",
    "        super().rotate(source, dest)\n",
    "        if os.path.exists(dest):\n",
    "            with open(dest,'rb') as f_in, gzip.open(dest + '.gz','wb') as f_out:\n",
    "                shutil.copyfileobj(f_in, f_out)\n",
    "            os.remove(dest)\n",
    "\n",
    "# (Demonstração, não substitui handler configurado previamente)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837f49d8",
   "metadata": {},
   "source": [
    "## 5. Função de Métricas e Fórmulas\n",
    "\n",
    "$Precision=\\frac{TP}{TP+FP}$  \\\n",
    "$Recall=\\frac{TP}{TP+FN}$  \\\n",
    "$F1=\\frac{2PR}{P+R}$\n",
    "\n",
    "Implementação simples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5967492b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "def compute_metrics(tp:int, fp:int, fn:int, tn:int|None=None) -> Dict[str,float]:\n",
    "    precision = tp / (tp + fp) if (tp+fp)>0 else 0.0\n",
    "    recall = tp / (tp + fn) if (tp+fn)>0 else 0.0\n",
    "    f1 = (2*precision*recall/(precision+recall)) if (precision+recall)>0 else 0.0\n",
    "    acc = None\n",
    "    if tn is not None:\n",
    "        acc = (tp + tn) / (tp + tn + fp + fn) if (tp+tn+fp+fn)>0 else 0.0\n",
    "    return {'precision':precision,'recall':recall,'f1':f1,'accuracy':acc}\n",
    "\n",
    "print(compute_metrics(10,5,2, tn=50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd03660a",
   "metadata": {},
   "source": [
    "## 6. Definir Espaço de Busca (Grid Search)\n",
    "Exemplo genérico de hiperparâmetros (ilustrativo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a612f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools, pandas as pd\n",
    "param_grid = {\n",
    "  'lr':[1e-4,1e-3],\n",
    "  'batch_size':[16,32],\n",
    "  'hidden':[64,128]\n",
    "}\n",
    "rows=[]\n",
    "for combo in itertools.product(*param_grid.values()):\n",
    "    rows.append(dict(zip(param_grid.keys(), combo)))\n",
    "param_df = pd.DataFrame(rows)\n",
    "param_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82eed31d",
   "metadata": {},
   "source": [
    "## 7. Função de Treinamento/Avaliação do Modelo (Exemplo)\n",
    "Usamos LogisticRegression do scikit-learn para demonstrar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916f9702",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import numpy as np, time\n",
    "\n",
    "X, y = make_classification(n_samples=1500, n_features=20, n_informative=8, random_state=42)\n",
    "Xtr, Xte, ytr, yte = train_test_split(X,y,test_size=0.3, random_state=42)\n",
    "\n",
    "def train_eval(params: dict):\n",
    "    start = time.time()\n",
    "    model = LogisticRegression(max_iter=500, C=1/params['lr'])\n",
    "    model.fit(Xtr, ytr)\n",
    "    pred = model.predict(Xte)\n",
    "    p = precision_score(yte, pred)\n",
    "    r = recall_score(yte, pred)\n",
    "    f1 = f1_score(yte, pred)\n",
    "    return {**params, 'precision':p,'recall':r,'f1':f1,'duration': time.time()-start}\n",
    "\n",
    "print(train_eval({'lr':1e-3,'batch_size':32,'hidden':64}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2672ac64",
   "metadata": {},
   "source": [
    "## 8. Executor de Grid Search Paralelo (joblib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a85cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "results = Parallel(n_jobs=-1)(delayed(train_eval)(row) for row in rows)\n",
    "len(results), results[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d577a483",
   "metadata": {},
   "source": [
    "## 9. Persistir e Carregar Resultados do Grid Search\n",
    "Salvamos JSONL + Parquet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99818616",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, pandas as pd, pyarrow as pa, pyarrow.parquet as pq, os\n",
    "res_df = pd.DataFrame(results)\n",
    "os.makedirs('../results', exist_ok=True)\n",
    "with open('../results/grid_results.jsonl','w') as f:\n",
    "    for rec in res_df.to_dict(orient='records'):\n",
    "        f.write(json.dumps(rec)+'\n",
    "')\n",
    "\n",
    "table = pa.Table.from_pandas(res_df)\n",
    "pq.write_table(table, '../results/grid_results.parquet')\n",
    "print('Persistido.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3876a5b3",
   "metadata": {},
   "source": [
    "## 10. Gerar Script Externo de Grid Search (arquivo .py)\n",
    "Criamos um script modular reutilizável."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b040c44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "script_code = '''#!/usr/bin/env python3\n",
    "import argparse, json, itertools, time, os\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "def train_eval(params, data):\n",
    "    Xtr, Xte, ytr, yte = data\n",
    "    start = time.time()\n",
    "    model = LogisticRegression(max_iter=500, C=1/params['lr'])\n",
    "    model.fit(Xtr, ytr)\n",
    "    pred = model.predict(Xte)\n",
    "    p = precision_score(yte, pred)\n",
    "    r = recall_score(yte, pred)\n",
    "    f1 = f1_score(yte, pred)\n",
    "    return {**params,'precision':p,'recall':r,'f1':f1,'duration': time.time()-start}\n",
    "\n",
    "def main():\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument('--out', default='results/gs_external.jsonl')\n",
    "    ap.add_argument('--n-jobs', type=int, default=-1)\n",
    "    args = ap.parse_args()\n",
    "    os.makedirs('results', exist_ok=True)\n",
    "    X,y = make_classification(n_samples=1200, n_features=20, n_informative=8, random_state=42)\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    Xtr,Xte,ytr,yte = train_test_split(X,y,test_size=0.3,random_state=42)\n",
    "    grid = { 'lr':[1e-4,1e-3], 'batch_size':[16,32], 'hidden':[64,128] }\n",
    "    combos = [dict(zip(grid.keys(), vals)) for vals in itertools.product(*grid.values())]\n",
    "    from joblib import Parallel, delayed\n",
    "    results = Parallel(n_jobs=args.n_jobs)(delayed(train_eval)(p,(Xtr,Xte,ytr,yte)) for p in combos)\n",
    "    with open(args.out,'w') as f:\n",
    "        for r in results: f.write(json.dumps(r)+'\\n')\n",
    "    print('Salvo em', args.out)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "'''\n",
    "with open('../grid_search_external.py','w') as f: f.write(script_code)\n",
    "print('Escrito grid_search_external.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0ac5ad",
   "metadata": {},
   "source": [
    "## 11. Notebook de Visualização: Carregar Resultados Salvos\n",
    "Carrega JSONL ou Parquet gerados anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8419da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, json\n",
    "from pathlib import Path\n",
    "jsonl_path = Path('../results/grid_results.jsonl')\n",
    "rows=[]\n",
    "if jsonl_path.exists():\n",
    "    with open(jsonl_path) as f:\n",
    "        for line in f:\n",
    "            rows.append(json.loads(line))\n",
    "vis_df = pd.DataFrame(rows)\n",
    "vis_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d837ee4a",
   "metadata": {},
   "source": [
    "## 12. Visualizações: Heatmap de Hiperparâmetros\n",
    "Pivot de f1 por lr x batch_size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059dff46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns, matplotlib.pyplot as plt\n",
    "if not vis_df.empty:\n",
    "    pivot = vis_df.pivot_table(index='lr', columns='batch_size', values='f1', aggfunc='mean')\n",
    "    plt.figure(figsize=(5,4))\n",
    "    sns.heatmap(pivot, annot=True, cmap='viridis', fmt='.3f')\n",
    "    plt.title('F1 por lr x batch_size')\n",
    "else:\n",
    "    print('DataFrame vazio para heatmap')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece9fe6c",
   "metadata": {},
   "source": [
    "## 13. Visualizações: Distribuições e Pareto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd39f355",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not vis_df.empty:\n",
    "    fig, ax = plt.subplots(1,2, figsize=(10,4))\n",
    "    vis_df['f1'].hist(ax=ax[0]); ax[0].set_title('Distribuição F1')\n",
    "    ax[1].scatter(vis_df['duration'], vis_df['f1']); ax[1].set_xlabel('Duração'); ax[1].set_ylabel('F1'); ax[1].set_title('Pareto tempo vs F1')\n",
    "else:\n",
    "    print('Sem dados para distribuições')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6532d4c",
   "metadata": {},
   "source": [
    "## 14. Visualizações: Evolução da Métrica\n",
    "Ordena execuções e mostra melhor cumulativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ac0e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not vis_df.empty:\n",
    "    vis_df = vis_df.copy().reset_index(drop=True)\n",
    "    best_so_far = vis_df['f1'].cummax()\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(vis_df.index, vis_df['f1'], label='F1 run')\n",
    "    plt.plot(vis_df.index, best_so_far, label='Melhor até aqui', linestyle='--')\n",
    "    plt.legend(); plt.xlabel('Execução'); plt.ylabel('F1'); plt.title('Evolução F1')\n",
    "else:\n",
    "    print('Sem dados para evolução')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ab2a14",
   "metadata": {},
   "source": [
    "## 15. Dashboard Interativo (Plotly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209de972",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "if not vis_df.empty:\n",
    "    try:\n",
    "        fig = px.scatter_3d(vis_df, x='lr', y='hidden', z='f1', color='batch_size', size='f1', title='Exploração 3D')\n",
    "        fig.show()\n",
    "    except Exception as e:\n",
    "        print('Plotly falhou:', e)\n",
    "else:\n",
    "    print('Sem dados para plot interativo')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45abf51f",
   "metadata": {},
   "source": [
    "## 16. Integração Logging + Resultados (Enriquecer Registros)\n",
    "Função para logar resumo formatado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad6de68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_result(record: dict):\n",
    "    logger.info('result', extra={'tag':'result','payload':record})\n",
    "\n",
    "if not vis_df.empty:\n",
    "    log_result(vis_df.sort_values('f1', ascending=False).iloc[0].to_dict())\n",
    "else:\n",
    "    logger.warning('Sem resultados para log_result')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b26812",
   "metadata": {},
   "source": [
    "## 17. Exportar Relatório Consolidado\n",
    "Gera markdown com top configuração e estatísticas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58947cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean, pstdev\n",
    "report_path = '../results/report.md'\n",
    "if not vis_df.empty:\n",
    "    top = vis_df.sort_values('f1', ascending=False).iloc[0]\n",
    "    stats = {\n",
    "        'f1_mean': vis_df['f1'].mean(),\n",
    "        'f1_std': vis_df['f1'].std(),\n",
    "        'f1_min': vis_df['f1'].min(),\n",
    "        'f1_max': vis_df['f1'].max(),\n",
    "        'n': len(vis_df)\n",
    "    }\n",
    "    md = ['# Relatório Grid Search', '\n",
    "', '## Top Configuração', '```', str(top.to_dict()), '```', '## Estatísticas', '```', json.dumps(stats, indent=2), '```']\n",
    "    with open(report_path, 'w') as f: f.write('\n",
    "'.join(md))\n",
    "    logger.info('Relatório gerado', extra={'report_path':report_path, 'top_f1': top['f1']})\n",
    "    print('Gerado', report_path)\n",
    "else:\n",
    "    print('Sem dados para relatório')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
