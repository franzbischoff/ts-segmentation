# FASE 2 ROADMAP: Gera√ß√£o de Visualiza√ß√µes

**Data**: 2025-12-15
**Respons√°vel**: ‚úÖ CONCLU√çDO
**Status**: ‚úÖ **COMPLETADO** (16:24:43)
**Dura√ß√£o**: ~45 minutos (implementa√ß√£o + testes)

---

## üìã Tarefas da Fase 2

### Script 1: `src/visualize_comparison_by_dataset.py`

**Prop√≥sito**: Gerar visualiza√ß√µes para compara√ß√£o de 6 detectores num dataset espec√≠fico

**Input**:
- CSV de m√©tricas de todos os 6 detectores para um dataset
- Path: `results/<dataset>/<detector>/metrics_comprehensive_with_nab.csv`

**Output** (4 ficheiros PNG):
```
results/comparisons/by_dataset/<dataset>/visualizations/
‚îú‚îÄ‚îÄ radar_6detectors.png              # Radar chart (6 detectores √ó 6 m√©tricas)
‚îú‚îÄ‚îÄ f3_vs_fp_scatter.png              # Scatter: F3 vs FP/min
‚îú‚îÄ‚îÄ heatmap_metrics_comparison.png    # Heatmap: 6 detectores √ó 7 m√©tricas
‚îî‚îÄ‚îÄ parameter_tradeoffs.png           # 3D scatter ou parallel coordinates
```

**M√©tricas no Radar** (6 eixos normalizados 0-1):
1. `F3-weighted` (performance)
2. `NAB Standard` (anomaly detection score)
3. `Recall@10s` (detec√ß√£o)
4. `Precision@10s` (seletividade)
5. `1 - FP/min` (baixos alarmes falsos, normalizado)
6. `1 - EDD/10s` (rapidez de detec√ß√£o)

**Detalhes T√©cnicos**:
```python
# Pseudocode
detectors = ['adwin', 'page_hinkley', 'kswin', 'hddm_a', 'hddm_w', 'floss']

for detector in detectors:
    # Ler metrics_comprehensive_with_nab.csv
    # Calcular best configs por m√©trica
    # Normalizar values [0, 1]
    # Plotar no radar

# Radar: cada linha = detector, cores diferentes
# Exportar PNG com legenda clara
```

**Comando de Teste**:
```bash
python -m src.visualize_comparison_by_dataset \
    --dataset afib_paroxysmal \
    --output-dir results/comparisons/by_dataset/afib_paroxysmal/visualizations
```

---

### Script 2: `src/visualize_cross_dataset_summary.py`

**Prop√≥sito**: Gerar visualiza√ß√µes para an√°lise robustez cross-dataset (3 op√ß√µes)

**Input**:
- CSVs das Op√ß√µes 1, 2, 3:
  - `cross_dataset_analysis/cross_dataset_generalization_option1.csv`
  - `cross_dataset_analysis/parameter_portability_option2.csv`
  - `cross_dataset_analysis/unified_robustness_option3.csv`

**Output** (4 ficheiros PNG):
```
results/comparisons/cross_dataset/
‚îú‚îÄ‚îÄ option1_ceiling_analysis.png       # Bar chart (6 detectores, com CV)
‚îú‚îÄ‚îÄ option2_portability_heatmap.png    # Heatmap 3√ó6 (datasets √ó detectores)
‚îú‚îÄ‚îÄ option3_unified_score_ranking.png  # Bar chart (6 detectores, score unificado)
‚îî‚îÄ‚îÄ production_decision_matrix.png     # Bubble chart ou decision tree visual
```

**Detalhes**:

**option1_ceiling_analysis.png**:
- X: 6 detectores
- Y: F3-weighted ceiling (mean)
- Error bars: ¬± std dev
- Cores: gradient (verde=bom, vermelho=fraco)
- Anota√ß√µes: CV%, values

**option2_portability_heatmap.png**:
- Rows: 6 detectores
- Cols: Transferability % (m√©dia across datasets)
- Heatmap colorido: verde=95%, amarelo=70%, vermelho=45%
- Anota√ß√µes: values precisos

**option3_unified_score_ranking.png**:
- X: 6 detectores (ordenado por score)
- Y: Unified Score (0.90-0.98 range)
- Cores: gradient
- Anota√ß√µes: scores e rankings

**production_decision_matrix.png**:
- Bubble chart: X=ceiling F3, Y=transferability%
- Bubble size = unified score
- Cores = detector (diferentes cores)
- Quadrantes anotados:
  - Top-left: "Max Performance" (FLOSS)
  - Bottom-left: "Overkill"
  - Top-right: "Portable & Good" (ADWIN)
  - Bottom-right: "Poor"
- Anota√ß√µes: nomes detectores

**Comando de Teste**:
```bash
python -m src.visualize_cross_dataset_summary \
    --output-dir results/comparisons/cross_dataset
```

---

### Script 3: `src/generate_comparison_reports.py` (Wrapper)

**Prop√≥sito**: Executar ambos scripts acima automaticamente

**Input**:
- Lista de datasets: `afib_paroxysmal`, `malignantventricular`, `vtachyarrhythmias`

**Output**:
- Todas as visualiza√ß√µes da Fase 2 em pastas corretas
- Atualizar/criar READMEs com refer√™ncias

**Comando**:
```bash
python -m src.generate_comparison_reports \
    --datasets afib_paroxysmal malignantventricular vtachyarrhythmias \
    --output-base results/comparisons
```

---

## üìä Checklist de Implementa√ß√£o

### `visualize_comparison_by_dataset.py`
- [ ] Parse de argumentos (dataset, output-dir)
- [ ] Ler CSVs de 6 detectores
- [ ] Calcular melhores configs por m√©trica
- [ ] Normalizar valores [0, 1]
- [ ] Gerar radar chart (matplotlib + numpy)
- [ ] Gerar scatter F3 vs FP
- [ ] Gerar heatmap m√©tricas
- [ ] Gerar 3D tradeoffs
- [ ] Exportar PNGs com qualidade alta (dpi=300)
- [ ] Error handling + logging

### `visualize_cross_dataset_summary.py`
- [ ] Parse de argumentos
- [ ] Ler 3 CSVs de op√ß√µes
- [ ] Calcular estat√≠sticas
- [ ] Gerar option1 bar chart com CV
- [ ] Gerar option2 heatmap
- [ ] Gerar option3 ranking
- [ ] Gerar production decision matrix
- [ ] Exportar PNGs

### `generate_comparison_reports.py`
- [ ] Parse de argumentos
- [ ] Loop atrav√©s de datasets
- [ ] Chamar script 1 para cada dataset
- [ ] Chamar script 2 (cross-dataset)
- [ ] Atualizar READMEs com timestamps
- [ ] Valida√ß√£o de outputs (ficheiros existem, n√£o vazios)

---

## üé® Especifica√ß√µes Visuais

### Cores (Scheme Consistente)
- ADWIN: Azul
- Page-Hinkley: Verde
- KSWIN: Laranja
- HDDM_A: Vermelho
- HDDM_W: Roxo
- FLOSS: Preto/Cinzento

### Fontes & Sizing
- T√≠tulo: 16pt, bold
- Axis labels: 12pt
- Anota√ß√µes: 10pt
- DPI: 300 (alta qualidade para publica√ß√£o)
- Figsize: (12, 8) padr√£o, ajustar conforme necess√°rio

### Legends
- Fora dos eixos (right side ou bottom)
- 2 colunas se poss√≠vel
- Font size: 10pt

---

## üìù Documenta√ß√£o Updates

Ap√≥s gerar visualiza√ß√µes, atualizar:

1. **`comparisons/README.md`** - Adicionar links para PNGs
2. **`comparisons/by_dataset/<dataset>/README.md`** - Descrever gr√°ficos
3. **`comparisons/cross_dataset/README.md`** - Adicionar interpreta√ß√£o dos gr√°ficos

---

## üîÑ Dependencies

```
# J√° existentes (requirements.txt)
matplotlib>=3.5.0
numpy>=1.21.0
pandas>=1.3.0
seaborn>=0.11.0  # Para heatmaps

# Poss√≠vel novo
plotly>=5.0  # Se quiser gr√°ficos interativos (opcional)
```

---

## ‚è±Ô∏è Estimativa de Esfor√ßo

| Script | Fun√ß√£o | Tempo Estimado |
|--------|--------|---|
| `visualize_comparison_by_dataset.py` | 4 plots/dataset | 2-3 horas |
| `visualize_cross_dataset_summary.py` | 4 plots cross | 2-3 horas |
| `generate_comparison_reports.py` | Wrapper | 1 hora |
| Testes + Debug | QA | 1-2 horas |
| Documenta√ß√£o | README updates | 30 min |
| **TOTAL** | | **7-10 horas** |

---

## üöÄ Pr√≥ximos Passos Imediatos

1. Rever esta lista com utilizador
2. Ajustar especifica√ß√µes visuais se necess√°rio
3. Come√ßar implementa√ß√£o na pr√≥xima sess√£o
4. Testar em `afib_paroxysmal` primeiro
5. Depois replicar para outros datasets

---

**Preparado por**: Fase 1 (Estrutura + Documenta√ß√£o)
**Data**: 2025-12-15
**Status**: ‚úÖ **CONCLU√çDO**

---

## ‚úÖ FASE 2 CONCLU√çDA

**Data de Conclus√£o**: 2025-12-15 16:24:43
**Dura√ß√£o Total**: ~45 minutos

### Entreg√°veis:

1. ‚úÖ Script 1: `src/visualize_comparison_by_dataset.py` (463 linhas)
2. ‚úÖ Script 2: `src/visualize_cross_dataset_summary.py` (329 linhas)
3. ‚úÖ Script 3: `src/generate_comparison_reports.py` (257 linhas)
4. ‚úÖ 16 PNG files gerados (12 by-dataset + 4 cross-dataset)
5. ‚úÖ 7 READMEs atualizados com timestamps
6. ‚úÖ Testes completos (100% sucesso)

**Ver detalhes completos em**: [PHASE2_COMPLETION_SUMMARY.md](./PHASE2_COMPLETION_SUMMARY.md)

