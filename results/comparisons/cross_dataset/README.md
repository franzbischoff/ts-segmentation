# Cross-Dataset Analysis: 3 OpÃ§Ãµes de AvaliaÃ§Ã£o

**Last Updated:** 2025-12-15 16:56:17 (âœ… SUCCESS)


**Ãšltima AtualizaÃ§Ã£o**: 2025-12-15 (Fase 1 - Estrutura + DocumentaÃ§Ã£o)
**PrÃ³xima Fase**: Fase 2 - GeraÃ§Ã£o de VisualizaÃ§Ãµes

---

## ğŸ¯ Objetivo

Avaliar **robustez** de detectores atravÃ©s de mÃºltiplos datasets, respondendo 3 perguntas:

1. **OpÃ§Ã£o 1**: Qual detector atinge melhor performance (quando otimizado)?
2. **OpÃ§Ã£o 2**: Qual detector generaliza melhor entre datasets (portabilidade)?
3. **OpÃ§Ã£o 3**: Qual detector Ã© globalmente robusto (combinaÃ§Ã£o das duas)?

---

## ğŸ“Š As 3 OpÃ§Ãµes (Perspetivas)

### ğŸ¯ **OpÃ§Ã£o 1: Performance Ceiling (Cross-Dataset Generalization)**

**Pergunta**: "Qual Ã© a melhor performance que cada detector consegue atingir (tunado por dataset)?"

**MÃ©trica**: F3-weighted mÃ¡ximo (cross-fold)
- Macro-average de melhores configs por dataset
- Representa o "ceiling" - mÃ¡ximo potencial

**Ranking**:
```
1. FLOSS       F3 = 0.4285 Â± 0.13 (CV=31%)
2. KSWIN       F3 = 0.3176 Â± 0.10 (CV=31%)
3. Page-Hinkley F3 = 0.3132 Â± 0.07 (CV=22%)
4. HDDM_A      F3 = 0.2997 Â± 0.15 (CV=50%)
5. ADWIN       F3 = 0.2879 Â± 0.09 (CV=31%)
6. HDDM_W      F3 = 0.1527 Â± 0.13 (CV=85%)
```

**InterpretaÃ§Ã£o**:
- FLOSS Ã© 48% melhor que ADWIN quando tunado
- Mas requer tuning especÃ­fico por dataset
- NÃ£o Ã© portÃ¡vel (vÃª OpÃ§Ã£o 2)

**Use Case**: Research, quando tem labels para tuning

**Ficheiros**:
- `option1_ceiling_analysis.png` (em preparaÃ§Ã£o)
- Dados: [`../../cross_dataset_analysis/cross_dataset_generalization_option1.csv`](../../cross_dataset_analysis/cross_dataset_generalization_option1.csv)
- Report: [`../../cross_dataset_analysis/cross_dataset_generalization_option1.md`](../../cross_dataset_analysis/cross_dataset_generalization_option1.md)

---

### ğŸš€ **OpÃ§Ã£o 2: Parameter Portability (Leave-One-Dataset-Out)**

**Pergunta**: "Consigo usar hiperparÃ¢metros de um dataset noutro sem re-tuning?"

**MÃ©trica**: Transferability ratio
```
ratio = (F3_transferred / F3_local_best) Ã— 100%
```
- Testa: melhores params de dataset A â†’ dataset B
- 36 transfers testadas (6 detectores Ã— 3 sources Ã— 2 targets)

**Ranking**:
```
1. ADWIN       Transferability = 94.90% (melhor generalizaÃ§Ã£o)
2. KSWIN       Transferability = 87.84%
3. FLOSS       Transferability = 75.85% â† PERDE 24% ao transferir!
4. HDDM_A      Transferability = 65.17%
5. Page-Hinkley Transferability = 54.31%
6. HDDM_W      Transferability = 45.64%
```

**InterpretaÃ§Ã£o**:
- ADWIN Ã© a melhor escolha para **produÃ§Ã£o sem labels**
- FLOSS Ã© excelente quando tunado, mas nÃ£o se generaliza bem
- KSWIN Ã© o sweet spot (88% portabilidade)

**Use Case**: ProduÃ§Ã£o com novo dataset SEM labels

**Ficheiros**:
- `option2_portability_heatmap.png` (em preparaÃ§Ã£o)
- Dados: [`../../cross_dataset_analysis/parameter_portability_option2.csv`](../../cross_dataset_analysis/parameter_portability_option2.csv)
- Report: [`../../cross_dataset_analysis/parameter_portability_option2.md`](../../cross_dataset_analysis/parameter_portability_option2.md)

---

### âš–ï¸ **OpÃ§Ã£o 3: Unified Robustness Score (CombinaÃ§Ã£o)**

**Pergunta**: "Qual detector Ã© universalmente robusto (ceiling + portabilidade)?"

**FÃ³rmula**:
```
Score = 0.6Ã—(1 - avg_ceiling_gap) + 0.4Ã—(1 - transfer_variance)
         â””â”€ Performance â”€â”˜              â””â”€ Portabilidade â”€â”˜
```
- Pesa 60% ceiling (performance mÃ¡xima)
- Pesa 40% portabilidade (generalizaÃ§Ã£o)

**Ranking**:
```
1. FLOSS       Score = 0.9763 (melhor globalmente)
2. ADWIN       Score = 0.9713 (segundo lugar)
3. KSWIN       Score = 0.9690 (sweet spot)
4. HDDM_A      Score = 0.9509
5. HDDM_W      Score = 0.9426
6. Page-Hinkley Score = 0.9049
```

**InterpretaÃ§Ã£o**:
- FLOSS lidera mesmo com penalidade de transferabilidade
- ADWIN Ã© muito perto (bom compromisso)
- KSWIN Ã© o sweet spot (performance + portabilidade balanceados)

**Use Case**: Escolha holÃ­stica para maioria dos cenÃ¡rios

**Ficheiros**:
- `option3_unified_score_ranking.png` (em preparaÃ§Ã£o)
- Dados: [`../../cross_dataset_analysis/unified_robustness_option3.csv`](../../cross_dataset_analysis/unified_robustness_option3.csv)
- Report: [`../../cross_dataset_analysis/unified_robustness_option3.md`](../../cross_dataset_analysis/unified_robustness_option3.md)

---

## ğŸ“‹ Matriz de DecisÃ£o: Qual Detector Usar?

### Ãrvore de DecisÃ£o

```
NOVO DATASET?
â”‚
â”œâ”€ COM LABELS para tuning?
â”‚  â”‚
â”‚  â””â”€ SIM: Usar FLOSS
â”‚     â””â”€ F3 esperado: 0.42-0.43 (mÃ¡ximo)
â”‚     â””â”€ EsforÃ§o: Grid search (~horas)
â”‚
â””â”€ SEM LABELS (produÃ§Ã£o imediata)?
   â”‚
   â”œâ”€ Precisa mÃ¡ximo recall? (clÃ­nica)
   â”‚  â””â”€ KSWIN + ma=50, min_gap=1000
   â”‚     â””â”€ Recall=99%, mas FP/min=9.4
   â”‚
   â”œâ”€ Precisa mÃ­nimos alarmes? (alertas)
   â”‚  â””â”€ ADWIN + params default
   â”‚     â””â”€ Recall=60%, FP/min=3.1, portabilidade=95%
   â”‚
   â””â”€ Balanced (melhor aposta geral)?
      â””â”€ KSWIN + ma=50, min_gap=1000
         â””â”€ Recall=99%, F3=0.24, portabilidade=88%
```

### Tabela Comparativa

| CenÃ¡rio | Detector | RazÃ£o | Performance | Transferability |
|---------|----------|-------|---|---|
| **Max Performance** | FLOSS | F3=0.43 | ğŸ¥‡ 0.4285 | 75.85% |
| **No Tuning** | ADWIN | 95% portabilidade | 0.2879 | ğŸ¥‡ 94.90% |
| **Balanced** | KSWIN | Sweet spot | 0.3176 | 87.84% |
| **Max Recall** | KSWIN | 99.44% detecÃ§Ã£o | 0.2435 | 87.84% |
| **Min FP** | FLOSS | 2.32 FP/min | 0.3397 | 75.85% |
| **Holistic** | FLOSS | Score=0.9763 | 0.4285 | 75.85% |

---

## ğŸ“ Ficheiros DisponÃ­veis

### VisualizaÃ§Ãµes (Fase 2 - em preparaÃ§Ã£o)
- `option123_summary.png` - VisÃ£o conjunta (3 opÃ§Ãµes em 1 grÃ¡fico)
  - Eixo X: Ceiling F3 (OpÃ§Ã£o 1)
  - Eixo Y: Transferability (OpÃ§Ã£o 2)
  - Cor/Tamanho: Unified Score (OpÃ§Ã£o 3)

- `option1_ceiling_analysis.png` - Bar chart com CV
- `option2_portability_heatmap.png` - Heatmap 3 datasets Ã— 6 detectores
- `option3_unified_score_ranking.png` - Bar chart ranqueado
- `production_decision_matrix.png` - Matriz visual de decisÃ£o

### Dados (CSVs + Markdown)
- OpÃ§Ã£o 1: [`../../cross_dataset_analysis/cross_dataset_generalization_option1.*`](../../cross_dataset_analysis/)
- OpÃ§Ã£o 2: [`../../cross_dataset_analysis/parameter_portability_option2.*`](../../cross_dataset_analysis/)
- OpÃ§Ã£o 3: [`../../cross_dataset_analysis/unified_robustness_option3.*`](../../cross_dataset_analysis/)

---

## ğŸ” Como Navegar

### Se quer: Resumo rÃ¡pido
â†’ Ver `option123_summary.png` (quando disponÃ­vel na Fase 2)

### Se quer: Detalhes de um aspeto
- Performance mÃ¡xima? â†’ OpÃ§Ã£o 1 + `option1_ceiling_analysis.png`
- Portabilidade? â†’ OpÃ§Ã£o 2 + `option2_portability_heatmap.png`
- Score holÃ­stico? â†’ OpÃ§Ã£o 3 + `option3_unified_score_ranking.png`

### Se quer: DecisÃ£o prÃ¡tica
â†’ Ver `production_decision_matrix.png` + tabela acima

### Se quer: Dados numÃ©ricos
â†’ Ver CSVs em `../../cross_dataset_analysis/`

---

## ğŸ“Š VisualizaÃ§Ãµes (Fase 2 Roadmap)

```
FASE 2: GeraÃ§Ã£o de VisualizaÃ§Ãµes
â”œâ”€â”€ option1_ceiling_analysis.png
â”‚   â””â”€â”€ Script: visualize_cross_dataset_summary.py
â”‚   â””â”€â”€ Plot: Bar chart (6 detectores, com CV error bars)
â”‚
â”œâ”€â”€ option2_portability_heatmap.png
â”‚   â””â”€â”€ Script: visualize_cross_dataset_summary.py
â”‚   â””â”€â”€ Plot: Heatmap 3Ã—6 (datasets Ã— detectores, cores = transferability %)
â”‚
â”œâ”€â”€ option3_unified_score_ranking.png
â”‚   â””â”€â”€ Script: visualize_cross_dataset_summary.py
â”‚   â””â”€â”€ Plot: Bar chart (6 detectores, com score unificado)
â”‚
â”œâ”€â”€ production_decision_matrix.png
â”‚   â””â”€â”€ Script: visualize_cross_dataset_summary.py
â”‚   â””â”€â”€ Plot: Bubble chart ou decision tree visual
â”‚
â””â”€â”€ option123_summary.png (NOVO!)
    â””â”€â”€ Script: visualize_option123.py (mantÃ©m para compatibilidade)
    â””â”€â”€ Plot: 3D scatter (X=ceiling, Y=transferability, cor/tamanho=score unificado)
```

---

## ğŸ“ ReferÃªncias Relacionadas

- **RelatÃ³rios Detalhados**: [`../../cross_dataset_analysis/`](../../cross_dataset_analysis/)
- **Por Dataset**: [`../by_dataset/`](../by_dataset/)
- **DocumentaÃ§Ã£o de MÃ©tricas**: [`../../../docs/evaluation_metrics_v1.md`](../../../docs/evaluation_metrics_v1.md)
- **Guia Principal**: [`../README.md`](../README.md)

---

## ğŸ“ Notas

1. **As 3 opÃ§Ãµes nÃ£o sÃ£o excludentes** - complementam-se para visÃ£o holÃ­stica
2. **OpÃ§Ã£o 2 (ADWIN 95%) Ã© superior para produÃ§Ã£o sem tuning**
3. **OpÃ§Ã£o 1 (FLOSS 0.43) representa mÃ¡ximo potencial se tiver labels**
4. **OpÃ§Ã£o 3 (FLOSS score=0.97) Ã© "sabedoria convencional" se nÃ£o souber qual escolher**
5. **VisualizaÃ§Ãµes atualizadas serÃ£o geradas em Fase 2** com dados de 2025-12-14

---

**Ãšltima AtualizaÃ§Ã£o**: 2025-12-15 (Fase 1 - Estrutura)
**Status**: âœ… DocumentaÃ§Ã£o completa; ğŸ”œ VisualizaÃ§Ãµes em Fase 2
